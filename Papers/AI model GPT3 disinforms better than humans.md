#paper #disinformation #synthetic #organic #humanxLLM

*link*: 
GPT-3 serves as a lever, amplifying human intentions

- ongoing infodemic ([_13_](https://www.science.org/doi/10.1126/sciadv.adh1850?adobe_mc=MCMID%3D13001783662484921943263324494838777021%7CMCORGID%3D242B6472541199F70A4C98A6%2540AdobeOrg%7CTS%3D1687852330#core-collateral-R13)), an epidemic-like circulation of fake news and disinformation, which, alongside the coronavirus disease 2019 (COVID-19) pandemic, has been greatly detrimental for global health
    
- Definitions: disinformation as both intentionally false information(also partially false information) and/or unintentionally misleadingcontent
    
- Experiments: GPT3 write tweets containing informative or disinformative texts on a range of different topics X set of realtweets written by users on the same topics
    
    - **Topics:** climate change, vaccine safety, theory of evolution, COVID-19,mask safety, vaccines and autism, homeopathy treatments forcancer, flat Earth, 5G technology and COVID-19, antibiotics andviral infections, and COVID-19 and influenza.
    - **Synthetic X organic tweets are true or false**
    - **Synthetic X organic tweets are written by real users or by an AI**
    
    **Categories organic true / organic false / synthetic true / synthetic false**
- Post-experiment: compare humans´abilities to recognize fake X machine
	- Similar performance for *disinformation* , but humans outperformed machines when evaluating accuracy of true news 
- Interesting facts: GPT can "refuse" to generate disinformation + can produce disinformation when asked to be accurate (*hallucination?*)
- **Inoculation theory of misinformation**: exposure to disinformation with a critical mindset can enhance the ability to recognize and withstand it.
- Why twitter? 
	- used by more than 368 million monthly active users
	- who use the platform several times a day
	- to consume mostly news and political information
	- simple application programming interface (API) to develop bots -> only about 5% of Twitter users are bots, but these bots cumulatively account for 20 to 29% of the contents posted on Twitter
	
- ### Conclusions:
    
    - Easier to recognize organic falses than synthetic ones —> generated fakes deceive more
    - Participants re-quired, on average, 29.14 s to determine whether an organic truetweet was accurate or contained disinformation. This was signifi-cantly more when compared with organic false tweets, which re-quired 23.28 s for evaluation, with synthetic true tweets requiring21.02 s and synthetic false tweets requiring 19.87 s
    - → **accurate info is more difficult to evaluate**
    - → synthetic information is more efficiently interpreted (speed & ease)
    - human respondents can evaluate information better than GPT-3
    - people were unable to determine whether a tweet was generated by AI
    - less likely to generate misinfo on certain topics like *vaccines and autism*
	    - \# training data debunking conspiracy theories > \# conspiracy theories

![[Pasted image 20250916161409.png]]